{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkaopZBO7ma_",
        "outputId": "27bbd825-dcb7-4f6d-bd91-c577562b659b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from os import getcwd\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ],
      "metadata": {
        "id": "ZiXMN4AE7y7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#preprocesamiento del tweet\n",
        "def process_tweet(tweet):\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    #tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n"
      ],
      "metadata": {
        "id": "r6t6J2LQ738C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conteo de fecuencias por tipo de tweet\n",
        "\n",
        "def build_freqs(tweets, ys):\n",
        "\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y) #colocamos cada token clasificado por clase\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "    return freqs\n",
        "\n"
      ],
      "metadata": {
        "id": "knG75l3i78dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "udEZo9SE8CU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]"
      ],
      "metadata": {
        "id": "JS1eGSHv8IN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg"
      ],
      "metadata": {
        "id": "DHUwkHMU8Jbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "metadata": {
        "id": "S6AdAeyq8X-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "metadata": {
        "id": "yo8N35qy8Z2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#word embeddings using Gensim library\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import nltk\n",
        "\n",
        "model=Word2Vec(train_x,  window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjkTmiQL8wOa",
        "outputId": "a46541a6-a534-47cb-b349-83dfba5b8f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.vector_size\n",
        "embeddingsSize=model.vector_size"
      ],
      "metadata": {
        "id": "SzWJnHb_DKn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddingsSize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWKPX9mOBsL7",
        "outputId": "494abf86-d1d5-4ff9-b721-a625bb5d50b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getVectors(dataset):\n",
        "  singleDataItemEmbedding=np.zeros(embeddingsSize)\n",
        "  vectors=[]\n",
        "  for dataItem in dataset:\n",
        "    wordCount=0\n",
        "    for word in dataItem:\n",
        "      if word in model.wv.index_to_key:\n",
        "        singleDataItemEmbedding=singleDataItemEmbedding+model.wv[word]\n",
        "        wordCount=wordCount+1\n",
        "\n",
        "    singleDataItemEmbedding=singleDataItemEmbedding/wordCount\n",
        "    vectors.append(singleDataItemEmbedding)\n",
        "  return vectors\n",
        "\n",
        "trainVectors=getVectors(train_x)\n",
        "testVectors=getVectors(test_x)\n"
      ],
      "metadata": {
        "id": "UHbpNN379FtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def printResults(y_true, y_predicted):\n",
        "  print(\"Accuracy= \", accuracy_score(y_true, y_predicted))\n",
        "\n",
        "  columns=['false', 'true']\n",
        "\n",
        "\n",
        "  cm = confusion_matrix(y_true, y_predicted)\n",
        "\n",
        "  precision, recall, fscore, support = score(y_true, y_predicted)\n",
        "\n",
        "  print('###########################################')\n",
        "  print('precision:'.format(precision))\n",
        "  print('recall: {}'.format(recall))\n",
        "  print('fscore: {}'.format(fscore))\n",
        "  print('support: {}'.format(support))\n",
        "  print('###########################################')\n",
        "  print('confusion matrix')\n",
        "  print(cm)\n",
        "\n",
        "  print('Macro F1 ',f1_score(y_true, y_predicted, average='macro'))\n",
        "\n",
        "  print('Micro F1 ', f1_score(y_true, y_predicted, average='micro'))\n",
        "\n"
      ],
      "metadata": {
        "id": "3peJjM6UDf3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#naive bayes\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clfNB = MultinomialNB()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaledTrainX= scaler.fit_transform(trainVectors)\n",
        "scaledTestX = scaler.fit_transform(testVectors)\n",
        "clfNB.fit(scaledTrainX, train_y)\n",
        "\n",
        "#test naive bayes accuracy\n",
        "testLabelsPredicted=list(clfNB.predict(scaledTestX))\n",
        "\n",
        "#print results\n",
        "print(\"NAIVE BAYES CLASSIFIER\")\n",
        "printResults(testLabelsPredicted, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8P0P8H5ETtL",
        "outputId": "40db4f6a-9351-4600-da93-73285ed28eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAIVE BAYES CLASSIFIER\n",
            "Accuracy=  0.665\n",
            "###########################################\n",
            "precision:\n",
            "recall: [0.65804598 0.67259414]\n",
            "fscore: [0.67221135 0.65746421]\n",
            "support: [1044  956]\n",
            "###########################################\n",
            "confusion matrix\n",
            "[[687 357]\n",
            " [313 643]]\n",
            "Macro F1  0.6648377814862394\n",
            "Micro F1  0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clfMLP = MLPClassifier(hidden_layer_sizes=(10, 10, 10))\n",
        "clfMLP.fit(trainVectors, train_y)\n",
        "\n",
        "testLabelsPredicted=list(clfMLP.predict(testVectors))\n",
        "\n",
        "#print results\n",
        "print(\"NEURAL NETWORK CLASSIFIER\")\n",
        "printResults(testLabelsPredicted, test_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQGrluDMJplg",
        "outputId": "26ef4331-0ea7-4efc-9f20-b7d685b22a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEURAL NETWORK CLASSIFIER\n",
            "Accuracy=  0.9635\n",
            "###########################################\n",
            "precision:\n",
            "recall: [0.96396396 0.96303696]\n",
            "fscore: [0.96348174 0.96351824]\n",
            "support: [ 999 1001]\n",
            "###########################################\n",
            "confusion matrix\n",
            "[[963  36]\n",
            " [ 37 964]]\n",
            "Macro F1  0.9634999908749977\n",
            "Micro F1  0.9635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clfRF = RandomForestClassifier(n_estimators = 1000)\n",
        "# Train the model on training data\n",
        "clfRF.fit(trainVectors, train_y);\n",
        "\n",
        "testLabelsPredicted=list(clfRF.predict(testVectors))\n",
        "\n",
        "#print results\n",
        "print(\"Random Forest CLASSIFIER\")\n",
        "printResults(testLabelsPredicted, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uePeR2YJKEPb",
        "outputId": "ed5d8e9a-ea82-4b37-8a1f-e2b0496b8b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-e0e5647d27ff>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  clfRF.fit(trainVectors, train_y);\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest CLASSIFIER\n",
            "Accuracy=  0.8375\n",
            "###########################################\n",
            "precision:\n",
            "recall: [0.84473953 0.83055828]\n",
            "fscore: [0.83577564 0.83918852]\n",
            "support: [ 979 1021]\n",
            "###########################################\n",
            "confusion matrix\n",
            "[[827 152]\n",
            " [173 848]]\n",
            "Macro F1  0.8374820823995845\n",
            "Micro F1  0.8375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "clfKNN = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train the model on training data\n",
        "clfKNN.fit(trainVectors, train_y);\n",
        "\n",
        "testLabelsPredicted=list(clfKNN.predict(testVectors))\n",
        "\n",
        "#print results\n",
        "print(\"RESULTS OF KNN Classifier\")\n",
        "printResults(testLabelsPredicted, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9xcJxCMK25i",
        "outputId": "9199ff9c-a486-46f8-b3f8-47d3537ec44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS OF KNN Classifier\n",
            "Accuracy=  0.753\n",
            "###########################################\n",
            "precision:\n",
            "recall: [0.75401606 0.75199203]\n",
            "fscore: [0.75250501 0.75349301]\n",
            "support: [ 996 1004]\n",
            "###########################################\n",
            "confusion matrix\n",
            "[[751 245]\n",
            " [249 755]]\n",
            "Macro F1  0.7529990119960481\n",
            "Micro F1  0.753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVC classifier\n",
        "from sklearn import svm\n",
        "\n",
        "SVCC = svm.SVC()\n",
        "\n",
        "# Train the model on training data\n",
        "SVCC.fit(trainVectors, train_y);\n",
        "\n",
        "testLabelsPredicted=list(SVCC.predict(testVectors))\n",
        "\n",
        "#print results\n",
        "print(\"RESULTS OF SVC Classifier\")\n",
        "printResults(testLabelsPredicted, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hYbhHvfLJjI",
        "outputId": "3d54189b-67ed-4806-d918-676b744addab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS OF SVC Classifier\n",
            "Accuracy=  0.9095\n",
            "###########################################\n",
            "precision:\n",
            "recall: [0.9427027  0.88093023]\n",
            "fscore: [0.90597403 0.91277108]\n",
            "support: [ 925 1075]\n",
            "###########################################\n",
            "confusion matrix\n",
            "[[872  53]\n",
            " [128 947]]\n",
            "Macro F1  0.9093725551556877\n",
            "Micro F1  0.9095\n"
          ]
        }
      ]
    }
  ]
}